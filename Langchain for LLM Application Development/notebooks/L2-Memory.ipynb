{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f96ffd2",
   "metadata": {
    "height": 30
   },
   "source": [
    "# Langchain: Memory\n",
    "\n",
    "### Outline\n",
    "\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227e08ca",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2fa963",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d0c58",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87461823",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65afe25",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=llm_model, temperature=0.7)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d977ec4d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, I am Abhishek\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Abhishek, it's nice to meet you. I'm an artificial intelligence designed to assist with various tasks and answer questions. How can I assist you today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, I am Abhishek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1d00dd",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I am Abhishek\n",
      "AI: Hello Abhishek, it's nice to meet you. I'm an artificial intelligence designed to assist with various tasks and answer questions. How can I assist you today?\n",
      "Human: Can you tell what 5 + 5?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Certainly, 5 + 5 is equal to 10. Is there anything else you would like me to calculate for you, Abhishek?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you tell what 5 + 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd6fe04",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, I am Abhishek\n",
      "AI: Hello Abhishek, it's nice to meet you. I'm an artificial intelligence designed to assist with various tasks and answer questions. How can I assist you today?\n",
      "Human: Can you tell what 5 + 5?\n",
      "AI: Certainly, 5 + 5 is equal to 10. Is there anything else you would like me to calculate for you, Abhishek?\n",
      "Human: btw, do you remember my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, Abhishek, I remember your name. You introduced yourself at the beginning of our conversation.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"btw, do you remember my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b0cff0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, I am Abhishek\n",
      "AI: Hello Abhishek, it's nice to meet you. I'm an artificial intelligence designed to assist with various tasks and answer questions. How can I assist you today?\n",
      "Human: Can you tell what 5 + 5?\n",
      "AI: Certainly, 5 + 5 is equal to 10. Is there anything else you would like me to calculate for you, Abhishek?\n",
      "Human: btw, do you remember my name?\n",
      "AI: Yes, Abhishek, I remember your name. You introduced yourself at the beginning of our conversation.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be193b4",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi, I am Abhishek\\nAI: Hello Abhishek, it's nice to meet you. I'm an artificial intelligence designed to assist with various tasks and answer questions. How can I assist you today?\\nHuman: Can you tell what 5 + 5?\\nAI: Certainly, 5 + 5 is equal to 10. Is there anything else you would like me to calculate for you, Abhishek?\\nHuman: btw, do you remember my name?\\nAI: Yes, Abhishek, I remember your name. You introduced yourself at the beginning of our conversation.\"}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad347080",
   "metadata": {},
   "source": [
    "### Adding Specific Context to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc31e6c",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {'input': 'Hi'},\n",
    "    {'output': \"Hello! What's up!\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412ce2d6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: Hello! What's up!\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20436616",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: Hello! What's up!\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a34fe7",
   "metadata": {
    "height": 30
   },
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2bb207",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a5794c3",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context(\n",
    "    {'input': 'Hi'},\n",
    "    {'output': 'Hello! How are you?'},\n",
    ")\n",
    "memory.save_context(\n",
    "    {'input': 'I am Abhishek'},\n",
    "    {'output': 'Hello Abhishek! I am AI'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "181d5634",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hello! How are you?', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='I am Abhishek', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hello Abhishek! I am AI', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f828821",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: I am Abhishek\\nAI: Hello Abhishek! I am AI'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6d50fb0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09c57b06",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1cecde",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=llm_model,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(llm=llm, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed239f1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Abhishek, it's nice to meet you! My name is AI. How can I assist you today?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello! I am Abhishek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb57f2b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course, Abhishek! I understand your concerns. God Of War is a fantastic game that has received critical acclaim for its compelling story, immersive gameplay, and stunning visuals. It's definitely worth your time if you enjoy action-adventure games with a deep narrative. Additionally, playing video games can be a great way to unwind and relax after a long day. So go ahead and enjoy the game, Abhishek! You deserve it.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I am thinking of playing God Of War today on PS5 but worried about wasting my time :( Can you console me?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4895da97",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Not at all, Abhishek! You can call me whatever you like. I'm here to assist you in any way I can.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Thanks Ava! This helped me get over the guilt. Do you mind if I call you Ava?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86aad5a3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, your name is Abhishek.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"btw, qq, Do you remember my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2ab755",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you! I am designed to be efficient with memory usage, so even with a small buffer, I can still retain important information like your name. Is there anything else I can assist you with?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Pretty impressive since I set your buffer memory to be just 1. Hmmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb374a5d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, of course! Your name is in my database and I can recall it whenever you interact with me. It's important for me to remember important details about our interactions so that I can provide the best possible assistance. Is there anything else you need help with?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Yep. One more time, do you really remember my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bd310be",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Yep. One more time, do you really remember my name?\\nAI: Yes, of course! Your name is in my database and I can recall it whenever you interact with me. It's important for me to remember important details about our interactions so that I can provide the best possible assistance. Is there anything else you need help with?\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec7eb2",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b3325d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fbcd77c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ef0e40c",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=22)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f605c3a4",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e268059",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67c1d49d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5dc74c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "memory_llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8604d008",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1fc62cc",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b86edc97",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=llm_model)\n",
    "conversation = ConversationChain(llm=llm, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad706684",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI, I do not have access to your personal devices such as your PlayStation. Therefore, I cannot add playing God of War to your schedule. Is there anything else I can help you with?\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can you add playing god of war on my playstation to my schedule?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0903205",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I am already functioning as your personal assistant. I can help you with scheduling, sending emails, setting reminders, and providing information on various topics. Is there anything specific you would like me to assist you with?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Oh can you please work as my personal assistant too?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed4877a8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize if my previous response came off as rude. As an AI, I do not have emotions or intentions, but I understand your point. If playing games is part of your work, I can certainly assist you with that. Is there a specific time you would like me to schedule for playing God of War on your PlayStation?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Actually, I am a game developer so playing games is part of my work smartass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b548495c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI discuss their schedule for the day, including meetings with the product team and a customer interested in AI developments. The human asks the AI to add playing a video game to their schedule, but the AI explains it cannot access personal devices. The human then asks if the AI can function as their personal assistant, to which the AI responds that it already is and can assist with scheduling, emails, reminders, and information. The AI asks if there is anything specific the human needs help with.\\nHuman: Actually, I am a game developer so playing games is part of my work smartass\\nAI: I apologize if my previous response came off as rude. As an AI, I do not have emotions or intentions, but I understand your point. If playing games is part of your work, I can certainly assist you with that. Is there a specific time you would like me to schedule for playing God of War on your PlayStation?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe9c2c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700498b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
